{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDm6dCbbPfGy"
      },
      "source": [
        "# Recitation: Introduction to PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlRU0ZTkPs7_"
      },
      "source": [
        "### 0. Plan\n",
        "- Introduce the PyTorch library and the automatic differentiation methods presented in it\n",
        "- Write multiple machine learning methods using this library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGYsI-0uQ0uD"
      },
      "source": [
        "### 1. Google Colab\n",
        "- Remotely launched Jupyter notebook.\n",
        "- You can perform calculations on the GPU, TPU, and this is very good in the era of the mining boom (12 hours per session are given).\n",
        "- Don't forget to select the option to run with GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj5I7q3yX8T7"
      },
      "source": [
        "### 2. PyTorch - NumPy with Automatic Differentiation, GPU Acceleration, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KcXNQ9YHEh"
      },
      "source": [
        "#### Peculiarities\n",
        "- Almost identical to NumPy in working with tensors\n",
        "- Supports GPU computing\n",
        "- Supports automatic differentiation\n",
        "- Gives high-level capabilities for working with neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9pFnYibs_sC"
      },
      "source": [
        "### 2.1 PyTorch API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyvDMdoULaFq",
        "outputId": "23bdf54e-32a0-4471-c3ff-2356f47ef3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version:2.8.0+cu126\n",
            "\n",
            "Create a zero ndarray in NumPy:\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "\n",
            "Create a zero tensor in PyTorch:\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "print(f\"Torch version:{torch.__version__}\")\n",
        "\n",
        "print(\"\\nCreate a zero ndarray in NumPy:\")\n",
        "zero_np = np.zeros([2, 3])\n",
        "print(zero_np)\n",
        "print(\"\\nCreate a zero tensor in PyTorch:\")\n",
        "zero_pt = torch.zeros([2,3])\n",
        "print(zero_pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_xvbMCate5d"
      },
      "source": [
        "You can access elements of tensors in the same way as in the case of Numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7MJM4_0LaFr",
        "outputId": "87786b81-fb6e-4486-ffa9-2a99d3200fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " numpy: zero_np[0,1]: 0.0\t(type: <class 'numpy.float64'>)\n",
            "\n",
            " torch: zero_pt[0,1]: 0.0\t(type: <class 'torch.Tensor'> / shape: torch.Size([])\n",
            "\n",
            "\tzero_pt[0,1].item(): 0.0\t(type: <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "print(f\" numpy: zero_np[0,1]: {zero_np[0, 1]}\\t(type: {type(zero_np[0, 1])})\\n\")\n",
        "print(f\" torch: zero_pt[0,1]: {zero_pt[0,1]}\\t(type: {type(zero_pt[0,1])} / shape: {zero_pt[0,1].shape}\\n\")\n",
        "print(f\"\\tzero_pt[0,1].item(): {zero_pt[0,1].item()}\\t(type: {type(zero_pt[0,1].item())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hiJvuLbuS1V"
      },
      "source": [
        "You can conveniently convert Numpy arrays and Torch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDbaXg7JQz_L",
        "outputId": "5bad1b34-f94c-456a-d1e9-5d03d50d1d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turn a ndarray into a tensor with 'torch.tensor()':\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float64)\n",
            "\n",
            "or 'torch.from_numpy():'\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float64)\n",
            "\n",
            "Turn a tensor into ndarray with '.numpy()':\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(\"Turn a ndarray into a tensor with 'torch.tensor()':\")\n",
        "zero_pt_from_np = torch.tensor(zero_np)\n",
        "print(zero_pt_from_np)\n",
        "print(\"\\nor 'torch.from_numpy():'\")\n",
        "zero_pt_from_np = torch.from_numpy(zero_np)\n",
        "print(zero_pt_from_np)\n",
        "\n",
        "print(\"\\nTurn a tensor into ndarray with '.numpy()':\")\n",
        "zero_np_from_pt = zero_pt.numpy()\n",
        "print(zero_np_from_pt)\n",
        "print(type(zero_np_from_pt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlJIUpXIvdjB"
      },
      "source": [
        "The library structure allows you to mix between calculators using the `.to()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaNvwewnLaFr",
        "outputId": "6a274f29-ee7a-4c8b-a364-704de06c512b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial device:\t'cpu'\n"
          ]
        }
      ],
      "source": [
        "t = torch.randn(2)\n",
        "print(f\"Initial device:\\t'{t.device}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYmuQPwODHmJ",
        "outputId": "f863b467-5be8-42fb-8a64-c30d8d042822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Move to gpu:\t'cuda:0'\n"
          ]
        }
      ],
      "source": [
        "t = t.to('cuda')\n",
        "print(f\"Move to gpu:\\t'{t.device}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INz4NvYDweHA",
        "outputId": "3f2e252c-88c6-41bb-f5e4-052ab597771e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Back to cpu:\t'cpu'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.6781589 ,  0.24914408], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "t = t.to('cpu')\n",
        "print(f\"Back to cpu:\\t'{t.device}'\")\n",
        "t.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "UxXRdhypworq"
      },
      "outputs": [],
      "source": [
        "#different devices\n",
        "t1 = torch.zeros(5).to(\"cuda\")\n",
        "t2 = torch.zeros(5).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "ZQwPeVTAxJeF",
        "outputId": "b9fe45a4-bd05-4aa4-e037-cd88aa2b4c8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3615663830.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# t1 + t2 ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# t1 + t2 ?\n",
        "t1 + t2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uvI9LAqypVt"
      },
      "source": [
        "Python supports various datatypes - `int`, `float`, `long`, `double` etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdXoKyFLzHn-",
        "outputId": "3b627dea-5cbb-41f4-e0ae-6cd87fe05aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of the created tensors - torch.LongTensor\n",
            "The type of the created tensors - torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "# types\n",
        "\n",
        "t = torch.arange(10)\n",
        "print(f\"The type of the created tensors - {t.type()}\")\n",
        "\n",
        "t1 = t.float() #.int() .long() .double()\n",
        "print(f\"The type of the created tensors - {t1.type()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2utEA3tK0-rN",
        "outputId": "23a49192-7afd-48d1-9b4f-7e296969291b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of the sum torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "# operations with different types\n",
        "\n",
        "print(f\"The type of the sum {(t + t1).type()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h8ak7NBxN6T",
        "outputId": "3e832c55-514c-41a6-a770-c215c52df1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The range : \n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
            "\n",
            "The reshaped tensor : \n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11]])\n",
            "\n",
            "Shape of the reshaped tensor : \n",
            "torch.Size([6, 2])\n",
            "\n",
            "The reshaped tensor : \n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "# reshape\n",
        "\n",
        "t = torch.arange(12)\n",
        "\n",
        "print(f\"The range : \\n{t}\\n\")\n",
        "print(f\"The reshaped tensor : \\n{t.view(6, 2)}\\n\")\n",
        "print(f\"Shape of the reshaped tensor : \\n{t.view(6, 2).shape}\\n\")\n",
        "print(f\"The reshaped tensor : \\n{t.view(2, 6)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpF4tVCg1o0_",
        "outputId": "8d76bd5e-5958-4de9-d388-2d42c801bb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The source tensor : \n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11]])\n",
            "\n",
            "The transposed tensor : \n",
            "tensor([[ 0,  2,  4,  6,  8, 10],\n",
            "        [ 1,  3,  5,  7,  9, 11]])\n"
          ]
        }
      ],
      "source": [
        "# permute\n",
        "\n",
        "t = torch.arange(12).view(6, 2)\n",
        "\n",
        "print(f\"The source tensor : \\n{t}\\n\")\n",
        "print(f\"The transposed tensor : \\n{t.permute(1, 0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o5GG0gbArbR",
        "outputId": "fc8e4686-cf24-4d1b-ba57-ea8efeb67245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11]]) torch.Size([6, 2])\n",
            "tensor([[ 0,  2,  4,  6,  8, 10],\n",
            "        [ 1,  3,  5,  7,  9, 11]]) torch.Size([2, 6])\n",
            "tensor([[ 0,  2,  4,  6,  8, 10],\n",
            "        [ 1,  3,  5,  7,  9, 11]]) torch.Size([2, 6])\n"
          ]
        }
      ],
      "source": [
        "# transpose\n",
        "\n",
        "a = torch.arange(12).view(6, 2)\n",
        "\n",
        "print(a, a.shape)\n",
        "\n",
        "b = torch.transpose(a, 0, 1)\n",
        "\n",
        "print(b, b.shape)\n",
        "\n",
        "c = a.T\n",
        "\n",
        "print(c, c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nZUtM6J2s4_",
        "outputId": "89cdbff7-487b-4204-b0a9-ab628997f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The torch.matmul() result : \n",
            "tensor([[110, 125],\n",
            "        [290, 341]])\n",
            "\n",
            "The @ result : \n",
            "tensor([[110, 125],\n",
            "        [290, 341]])\n",
            "\n",
            "The torch.einsum result : \n",
            "tensor([[110, 125],\n",
            "        [290, 341]])\n"
          ]
        }
      ],
      "source": [
        "# matrix multiplication\n",
        "\n",
        "a = torch.arange(12).view(6, 2)\n",
        "b = torch.arange(12).view(2, 6)\n",
        "\n",
        "\n",
        "print(f\"The torch.matmul() result : \\n{torch.matmul(b, a)}\\n\")\n",
        "print(f\"The @ result : \\n{b @ a}\\n\")\n",
        "print(f\"The torch.einsum result : \\n{torch.einsum('ij,jk->ik', b, a)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa6MMjiU5Orm",
        "outputId": "7f0edd76-3a53-43d8-d605-9c319c3b819c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dot product of the vectors - 285\n",
            "The dot product of the vectors - 285\n"
          ]
        }
      ],
      "source": [
        "# dot product\n",
        "\n",
        "a = torch.arange(10)\n",
        "b = a\n",
        "\n",
        "print(f\"The dot product of the vectors - {a.dot(b)}\")\n",
        "print(f\"The dot product of the vectors - {a @ b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCRrQ-6T2SaL"
      },
      "source": [
        "### 3. Automatic differentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dkkgv-h6M9R"
      },
      "source": [
        "PyTorch allows you to dynamically create a computation graph that can run efficiently on GPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0EO8A7hJ2l6L"
      },
      "outputs": [],
      "source": [
        "# chose device automaticaly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZSGQms36oWV"
      },
      "source": [
        "For variables, we can specify whether a gradient should be computed for it using the `requires_grad` flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZITBteuU6nxk",
        "outputId": "62a8ca44-e215-40c6-b152-4ca3a3ca2acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "param:  tensor([1.], requires_grad=True) \n",
            "data:  tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "data = torch.tensor([1.], requires_grad=False)\n",
        "param = torch.tensor([1.], requires_grad=True)\n",
        "print('param: ', param, '\\ndata: ', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "I-k1Rwzc6iux",
        "outputId": "f37208c7-9a55-4661-a7c2-cc642ab5a9bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Only Tensors of floating point and complex dtype can require gradients",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-189546185.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we can compute gradient only for floats and complex types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
          ]
        }
      ],
      "source": [
        "# we can compute gradient only for floats and complex types\n",
        "data_long = torch.tensor([1], requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LELHTmSy8LVh",
        "outputId": "c5d97a66-cab2-4c00-ff03-26ee0e299be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The var data with required grad - tensor([1.], requires_grad=True)\n",
            "The var data without required grad - tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "# set requires grad\n",
        "\n",
        "data = data.requires_grad_(True)\n",
        "\n",
        "print(f\"The var data with required grad - {data}\")\n",
        "\n",
        "data = data.requires_grad_(False)\n",
        "\n",
        "print(f\"The var data without required grad - {data}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7IOKLTu9cFH"
      },
      "source": [
        "Let's look at how to calculate derivatives using PyTorch using an example function.\n",
        "\n",
        "\n",
        "$$\n",
        "f(\\mathbf{x}) = ||  A \\mathbf{x}  + b - \\mathbf{y} ||_2\n",
        "$$\n",
        "\n",
        "$$\n",
        " \\frac{\\partial f}{\\partial \\mathbf{b}} = 2 (A \\mathbf{x}  + b - \\mathbf{y})\n",
        "$$\n",
        "<!--\n",
        "$$\n",
        " \\frac{\\partial f}{\\partial \\mathbf{x}} = 2 (A \\mathbf{x}  + b - \\mathbf{y}) A^\\top\n",
        "$$ -->\n",
        "\n",
        "$$\n",
        " \\frac{\\partial f}{\\partial \\mathbf{A}} = 2 (A \\mathbf{x}  + b - \\mathbf{y})x^\\top\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "3U8DMCWa9CNZ"
      },
      "outputs": [],
      "source": [
        "def f(x, y, A, b):\n",
        "  return torch.sum((A@x + b  - y)**2)\n",
        "\n",
        "def dfdb(x, y, A, b):\n",
        "  return 2*(A@x + b  - y)\n",
        "\n",
        "def dfda(x, y, A, b):\n",
        "  return torch.outer(2*(A@x + b  - y), x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_o5wuz0JqwoM"
      },
      "outputs": [],
      "source": [
        "# variables\n",
        "\n",
        "x = torch.rand(3, requires_grad=False)\n",
        "y = torch.rand(3, requires_grad=False)\n",
        "A = torch.rand((3, 3), requires_grad=True)\n",
        "b = torch.rand(3, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QlL5nDKGrz8W"
      },
      "outputs": [],
      "source": [
        "# want to turn off any grad-related computations\n",
        "\n",
        "with torch.no_grad():\n",
        "  val = f(x, y, A, b)\n",
        "  d_b = dfdb(x, y, A, b)\n",
        "  d_a = dfda(x, y, A, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn5dYuQIArbS",
        "outputId": "3aeefd5e-f61b-44f6-9003-04e71ba14935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A.grad:\n",
            "None\n",
            "\n",
            "b.grad:\n",
            "None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Forward pass\n",
        "val = f(x, y, A, b) # computation graph is built\n",
        "print(f\"A.grad:\\n{A.grad}\\n\")\n",
        "print(f\"b.grad:\\n{b.grad}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC0tzB5-ArbS",
        "outputId": "547c7f3a-b826-48ff-bda6-9eaf77b9ba2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A.grad:\n",
            "tensor([[0.0658, 0.9637, 0.4602],\n",
            "        [0.0806, 1.1804, 0.5636],\n",
            "        [0.0193, 0.2834, 0.1353]])\n",
            "\n",
            "b.grad:\n",
            "tensor([1.1098, 1.3593, 0.3263])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Backward pass\n",
        "val.backward() # gradients are computed and stored\n",
        "print(f\"A.grad:\\n{A.grad}\\n\")\n",
        "print(f\"b.grad:\\n{b.grad}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Jqv4_zgkue1Y",
        "outputId": "4be1b593-8e0a-4765-e742-725575d12de2",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1839383640.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "# what if we try to compute backward when we turn off grad computations\n",
        "with torch.no_grad():\n",
        "    val = f(x, y, A, b)\n",
        "val.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3kemRxgt0Qe",
        "outputId": "9b30d5c2-b7a0-4025-8a00-4abe924213ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "for v, g in zip([A, b], [d_a, d_b]):\n",
        "  print(torch.norm(v.grad - g))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "VjEjuk722e2T",
        "outputId": "20ab186d-812c-40df-dc26-32e512750a4b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1718984200.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# can we call backward twice?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "# can we call backward twice?\n",
        "val.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "mjOhzmTY5iQR"
      },
      "outputs": [],
      "source": [
        "# what if we do we same thing again?\n",
        "val = f(x, y, A, b) # Forward\n",
        "val.backward() # Backward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IZPqeX52nMq",
        "outputId": "8bf300d2-1736-4325-df40-e4c39c76a8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The diff between the autograd and the analytical one \t 1.7208566665649414\n",
            "Has it been doubled \t True\n",
            "The diff between the autograd and the analytical one \t 1.7848868370056152\n",
            "Has it been doubled \t True\n"
          ]
        }
      ],
      "source": [
        "for v, g in zip([A, b], [d_a, d_b]):\n",
        "  print(f\"The diff between the autograd and the analytical one \\t {torch.norm(v.grad - g)}\")\n",
        "  print(f\"Has it been doubled \\t {torch.norm(v.grad - 2*g) < 1e-8}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "VenUGMgp4K9C"
      },
      "outputs": [],
      "source": [
        "def set_zero_grad(vars):\n",
        "  for var in vars:\n",
        "    if var.grad is not None:\n",
        "      var.grad.data.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1xyWXBzg3S58"
      },
      "outputs": [],
      "source": [
        "set_zero_grad([A, b, x, y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK3DPP1y48M4",
        "outputId": "c2322c1d-1f0d-46ef-d9cf-3134e79fc489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "val = f(x, y, A, b)\n",
        "val.backward()\n",
        "\n",
        "for v, g in zip([A, b], [d_a, d_b]):\n",
        "  print(torch.norm(v.grad - g))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhdnWNdLA8JL"
      },
      "source": [
        "Now, we will use PyTorch to implement and train a toy neural network on the FashionMNIST dataset!\n",
        "\n",
        "## Section 4. DataSet and DataLoader\n",
        "\n",
        "To build a neural network and its training pipeline, we need to define both the **dataset** and the **model**.\n",
        "\n",
        "PyTorch provided a utility class `DataSet` and `DataLoader` where we can inherit from and define our own type of dataset.\n",
        "\n",
        "* `DataSet` - Define the dataset, specifically, provide a data structure that tells\n",
        "  1. How much data are there in the dataset - `__len__(self) -> int`\n",
        "  2. What is the `i`-th data in the dataset - `__getitem__(self, int) -> Data`\n",
        "\n",
        "\n",
        "* `DataLoader` - Given a dataset, how are we going to use these data\n",
        "  1. Do we want to shuffle it?\n",
        "  2. Do we want to read them in batch, what is the batch size?\n",
        "\n",
        "In the toy demo below, we will use the `FashionMNIST` dataset provided in torchvision package.\n",
        "\n",
        "Specifically, the `datasets.FashionMNIST` is a subclass of `DataSet`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQkH4olGaohE"
      },
      "source": [
        "The dataset includes all images in the train and validation set. The dataloader samples the dataset according to the batch size for training and validation. Let's take a look at one of the images in the train set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFZ7YP2bArbc",
        "outputId": "788e2031-92ce-4d87-bdd7-edd314968995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.8MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 176kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.21MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 26.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Datasets\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "egR4eyNHArbc"
      },
      "outputs": [],
      "source": [
        "# Dataloaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "2lw1rNmjagL8",
        "outputId": "faf1ea1f-f981-4c82-f02f-86717ef6447c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 5\n"
          ]
        }
      ],
      "source": [
        "# Display one image\n",
        "\n",
        "# get batch and labels\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "\n",
        "# get image\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "\n",
        "# plot\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6XwrY-tBCRF"
      },
      "source": [
        "## Section 5. Toy Demo on FashionMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml95NkAkbEbm"
      },
      "source": [
        "Now we're ready to build a neural network using Pytorch.\n",
        "\n",
        "For this we will use the modules provided in `torch.nn.` In particular we'll be using `nn.Linear`, which corresponds to a linear layer and `nn.Sigmoid` which applies the sigmoid function to all entries in the tensor element-wise.\n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "ni64vI-lbDi_"
      },
      "outputs": [],
      "source": [
        "# define a model\n",
        "\n",
        "class FashionMNISTModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lin1 = torch.nn.Linear(784, 784)\n",
        "    self.sigm = torch.nn.Sigmoid()\n",
        "    self.lin2 = torch.nn.Linear(784, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.lin1(x)\n",
        "    x = self.sigm(x)\n",
        "    x = self.lin2(x)\n",
        "    x = self.sigm(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1UfseNguoK"
      },
      "source": [
        "We're now ready to write a training loop for our model.\n",
        "\n",
        "First, we need to set some hyperparameters. The number of epochs specifies how many times we'll traverse the training set while the learning rate controls the step size for each gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "flZ6EzOLchVg"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# set hyper parameters for training\n",
        "lr = 0.001\n",
        "epochs = 10\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0FTsRxShFMB"
      },
      "source": [
        "Next, we have to instantiate our model, the stochastic gradient descent optimizer, and the loss function.\n",
        "\n",
        "The loss function we'll be using in our case is Cross Entropy loss. Here, we compute the average loss per sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "U3dAfCD2crsN"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "model = FashionMNISTModel()\n",
        "model.to(device)\n",
        "\n",
        "# initialize optimizer for SGD\n",
        "optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# intialize loss metric\n",
        "loss_func = torch.nn.CrossEntropyLoss(reduction='mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRz4n3yFi5oA"
      },
      "source": [
        "Next we can write a loop to iterate through the data to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "161KROowhfLy"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, loader, optimizer, loss_func, epoch, train=False):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    label = 'Training' if train else 'Test'\n",
        "\n",
        "    for imgs, labels in tqdm(loader, desc=f'{label} Epoch: {epoch}'):\n",
        "        optim.zero_grad()\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # reshape input\n",
        "        imgs = imgs.reshape(imgs.shape[0], -1)\n",
        "        # Forward\n",
        "        out = model(imgs)\n",
        "        # compute loss\n",
        "        loss = loss_func(out, labels)\n",
        "        preds = torch.argmax(out, dim=-1)\n",
        "        # compute accuracy\n",
        "        acc = torch.sum(preds == labels)\n",
        "\n",
        "        # Perform gradient descent if we're training\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "        # log total loss\n",
        "        total_loss += imgs.shape[0] * loss\n",
        "        n_samples += imgs.shape[0]\n",
        "        total_correct += acc\n",
        "\n",
        "    return total_loss / n_samples, total_correct / n_samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Q_t_pche_y"
      },
      "source": [
        "Putting it all together, let's train a feed-forward network on the FashionMNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "yelE2Kkti3CG",
        "outputId": "409e2532-a4e6-43b0-9e6a-1662bc816b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch: 0:  11%|█         | 99/938 [00:00<00:06, 131.96it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2606791998.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# set model in training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# test loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4046696757.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, loader, optimizer, loss_func, epoch, train)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Training'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{label} Epoch: {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typestr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_conv_type_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_conv_type_shape\u001b[0;34m(im)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_conv_type_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mextra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "test_losses = []\n",
        "for epoch in range(epochs):\n",
        "    # set model in training mode\n",
        "    model.train()\n",
        "    train_loss, train_acc = train_loop(model, train_dataloader, optim, loss_func, epoch=epoch, train=True)\n",
        "\n",
        "    # test loop\n",
        "    # set model in eval mode\n",
        "    model.eval()\n",
        "    test_loss, test_acc = train_loop(model, test_dataloader, optim, loss_func, epoch=epoch, train=False)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f\" Epoch {epoch}: Train loss: {round(train_loss.item(), 4)} |  Train acc: {round(train_acc.item(), 4)} | \\\n",
        "    Test loss: {round(test_loss.item(), 4)} | Test acc: {round(test_acc.item(), 4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-MV1o2lArbd"
      },
      "source": [
        "## Section 6. Pytorch model layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "wkbcjCcfArbd"
      },
      "outputs": [],
      "source": [
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W9vfCx4Arbd",
        "outputId": "a9f556bd-37ce-4ab0-8037-98aca070b305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRYeAtebArbd",
        "outputId": "2e6895dd-1c28-4ae6-f7fb-130d64ee44a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "# nn.Flatten\n",
        "\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwu4OhFwArbd",
        "outputId": "1c79867c-a2e7-4a38-e7dc-039d7891567c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "# nn.Linear\n",
        "\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgBTjKJ-Arbd",
        "outputId": "5adb6571-1109-48cd-ff2c-9c6aeca2b7b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[-0.1936,  0.4516, -0.0755,  0.5455, -0.1704,  0.0812,  0.3825,  0.2392,\n",
            "          0.3050, -0.1353,  0.5573,  0.4068,  0.1348,  0.0771, -0.1763,  0.1381,\n",
            "          0.0575,  0.1651,  0.3152,  0.4470],\n",
            "        [ 0.0486,  0.3493, -0.0228,  0.5947,  0.1014,  0.2827, -0.0789, -0.1446,\n",
            "         -0.2998,  0.2377,  0.5239,  0.1009, -0.1582, -0.1452,  0.0575, -0.1322,\n",
            "          0.0525, -0.1619,  0.0498,  0.3274],\n",
            "        [ 0.0831,  0.0594, -0.0467,  0.4829, -0.2319, -0.0785,  0.2660, -0.1820,\n",
            "          0.2454,  0.3959,  0.4773,  0.0083,  0.1409, -0.1676, -0.1471, -0.4161,\n",
            "          0.2465,  0.2181,  0.3450,  0.4437]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.0000, 0.4516, 0.0000, 0.5455, 0.0000, 0.0812, 0.3825, 0.2392, 0.3050,\n",
            "         0.0000, 0.5573, 0.4068, 0.1348, 0.0771, 0.0000, 0.1381, 0.0575, 0.1651,\n",
            "         0.3152, 0.4470],\n",
            "        [0.0486, 0.3493, 0.0000, 0.5947, 0.1014, 0.2827, 0.0000, 0.0000, 0.0000,\n",
            "         0.2377, 0.5239, 0.1009, 0.0000, 0.0000, 0.0575, 0.0000, 0.0525, 0.0000,\n",
            "         0.0498, 0.3274],\n",
            "        [0.0831, 0.0594, 0.0000, 0.4829, 0.0000, 0.0000, 0.2660, 0.0000, 0.2454,\n",
            "         0.3959, 0.4773, 0.0083, 0.1409, 0.0000, 0.0000, 0.0000, 0.2465, 0.2181,\n",
            "         0.3450, 0.4437]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# nn.ReLU\n",
        "\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEyNoZYAArbd",
        "outputId": "47398eb0-b154-4e64-f452-aa9fbe6a1bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1299,  0.2471, -0.0882, -0.1791, -0.1843,  0.0486,  0.0865, -0.2008,\n",
            "         -0.2500,  0.1274],\n",
            "        [ 0.1992,  0.0850, -0.0357, -0.1114, -0.0576,  0.0126, -0.0134, -0.3547,\n",
            "         -0.2139, -0.0399],\n",
            "        [ 0.2379,  0.1788, -0.1456,  0.0023, -0.0641,  0.0298,  0.0066, -0.1487,\n",
            "         -0.2329, -0.0521]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# nn.Sequential\n",
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "\n",
        "print(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJJzLYA2Arbd",
        "outputId": "d833f5d4-cd68-4eb7-b73b-b06a95cff63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1153, 0.1297, 0.0927, 0.0847, 0.0842, 0.1063, 0.1104, 0.0828, 0.0789,\n",
            "         0.1150],\n",
            "        [0.1274, 0.1136, 0.1007, 0.0934, 0.0985, 0.1057, 0.1030, 0.0732, 0.0843,\n",
            "         0.1003],\n",
            "        [0.1280, 0.1207, 0.0872, 0.1011, 0.0947, 0.1040, 0.1016, 0.0870, 0.0799,\n",
            "         0.0958]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# nn.Softmax\n",
        "\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "\n",
        "print(pred_probab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDnkqSQVArbe",
        "outputId": "5cd15eac-7d3a-422f-f43c-d941d033d9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: FashionMNISTModel(\n",
            "  (lin1): Linear(in_features=784, out_features=784, bias=True)\n",
            "  (sigm): Sigmoid()\n",
            "  (lin2): Linear(in_features=784, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "\n",
            "Layer: lin1.weight | Size: torch.Size([784, 784]) | Values : tensor([[ 0.0033,  0.0082, -0.0050,  ...,  0.0174, -0.0306, -0.0214],\n",
            "        [-0.0098, -0.0276, -0.0146,  ...,  0.0277,  0.0081, -0.0343]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: lin1.bias | Size: torch.Size([784]) | Values : tensor([0.0330, 0.0031], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: lin2.weight | Size: torch.Size([10, 784]) | Values : tensor([[ 0.0291, -0.0224, -0.0066,  ..., -0.0266,  0.0175, -0.0093],\n",
            "        [-0.0253,  0.0225, -0.0081,  ...,  0.0295, -0.0234, -0.0018]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: lin2.bias | Size: torch.Size([10]) | Values : tensor([ 0.0264, -0.0089], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Access model information\n",
        "\n",
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_wqEmEhArbe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}